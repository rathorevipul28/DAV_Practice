{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feature_sign_search(A, y, gamma):\n",
    "    basis_matrix = np.matmul(A.T, A)\n",
    "    x = np.zeros(basis_matrix.shape[0])\n",
    "    desired_correlation = np.dot(A.T, y)\n",
    "    theta_vector = np.zeros(basis_matrix.shape[0])\n",
    "    grad = (- 2 * desired_correlation) + (2 * np.matmul(basis_matrix, x))\n",
    "    active_set = set()\n",
    "    zero_opt_grad = 99999999999\n",
    "    nonzero_opt_grad = 0\n",
    "    while not((zero_opt_grad <= gamma) and (np.allclose(nonzero_opt_grad, 0))):     \n",
    "        if np.allclose(nonzero_opt_grad, 0):\n",
    "            i = np.argmax(np.abs(grad) * (theta_vector == 0))\n",
    "            if grad[i] > gamma:\n",
    "                theta_vector[i] = -1.\n",
    "                x[i] = 0\n",
    "                active_set.add(i)\n",
    "            elif grad[i] < -gamma:\n",
    "                theta_vector[i] = 1.\n",
    "                x[i] = 0\n",
    "                active_set.add(i)\n",
    "            if len(active_set) == 0:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        index = np.array(sorted(active_set))\n",
    "        constr_theta_vector = theta_vector[index]\n",
    "        constr_basis = basis_matrix[np.ix_(index, index)]\n",
    "        constr_correlation = desired_correlation[index]\n",
    "        x_dash = np.linalg.solve(constr_basis, (constr_correlation - gamma * constr_theta_vector / 2))\n",
    "        new_theta_vector = np.sign(x_dash)\n",
    "        constr_old_x = x[index]\n",
    "        theta_change_vector = np.where(abs(new_theta_vector - constr_theta_vector) > 1)[0]\n",
    "        if len(theta_change_vector)!= 0:\n",
    "            lowest_curr = x_dash\n",
    "            lowest_obj = (np.dot(y.T, y) + (np.dot(x_dash, np.dot(constr_basis, x_dash))\n",
    "                        - (2 * np.dot(x_dash, constr_correlation))) + (gamma * abs(x_dash).sum()))\n",
    "            \n",
    "            for j in theta_change_vector:\n",
    "                a = x_dash[j]\n",
    "                b = constr_old_x[j]\n",
    "                prop = b / (b - a)\n",
    "                curr = constr_old_x - (constr_old_x[j]) * (constr_old_x - x_dash)/(constr_old_x[j]-x_dash[j])\n",
    "                cost = np.dot(y.T, y) + (np.dot(curr, np.dot(constr_basis, curr))\n",
    "                              - 2 * np.dot(curr, constr_correlation)\n",
    "                              + gamma * abs(curr).sum())\n",
    "                \n",
    "                if cost < lowest_obj:\n",
    "                    lowest_obj = cost\n",
    "                    lowest_prop = prop\n",
    "                    lowest_curr = curr    \n",
    "        else:\n",
    "            lowest_curr = x_dash\n",
    "        x[index] = lowest_curr\n",
    "        zeros = index[np.abs(x[index]) < 1e-21]\n",
    "        x[zeros] = 0.\n",
    "        theta_vector[index] = np.sign(x[index])\n",
    "        active_set.difference_update(zeros)\n",
    "        grad = (- 2 * desired_correlation) + (2 * np.dot(basis_matrix, x))        \n",
    "        nonzero_opt_grad = np.max(abs(grad[theta_vector != 0] + gamma * theta_vector[theta_vector != 0]))\n",
    "        zero_opt_grad = np.max(abs(grad[theta_vector == 0]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For gamma = 0.1:- percentage of error in predicted value of y is = 12.7852503258\n",
      "And the corresponding coefficient vector is -\n",
      "[ 0.          0.05220713 -0.29892105  0.29956839  0.58385682  0.\n",
      "  0.          0.          0.          0.48542765]\n",
      "For gamma = 0.5:- percentage of error in predicted value of y is = 21.1178927471\n",
      "And the corresponding coefficient vector is -\n",
      "[0.03844489 0.         0.         0.17873377 0.39923106 0.\n",
      " 0.         0.         0.05740646 0.36948309]\n",
      "For gamma = 1:- percentage of error in predicted value of y is = 25.1460673019\n",
      "And the corresponding coefficient vector is -\n",
      "[0.         0.         0.         0.21141514 0.39745549 0.\n",
      " 0.         0.         0.01145319 0.32641625]\n",
      "For gamma = 2:- percentage of error in predicted value of y is = 36.0055419305\n",
      "And the corresponding coefficient vector is -\n",
      "[0.         0.         0.         0.21095544 0.32654033 0.\n",
      " 0.         0.         0.         0.2372075 ]\n",
      "For gamma = 4:- percentage of error in predicted value of y is = 62.6960869065\n",
      "And the corresponding coefficient vector is -\n",
      "[0.         0.         0.         0.19894945 0.17353271 0.\n",
      " 0.         0.         0.         0.0621008 ]\n",
      "For gamma = 6:- percentage of error in predicted value of y is = 88.8081477065\n",
      "And the corresponding coefficient vector is -\n",
      "[0.         0.         0.         0.12503442 0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "For gamma = 10:- percentage of error in predicted value of y is = 100.0\n",
      "And the corresponding coefficient vector is -\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "For gamma = 20:- percentage of error in predicted value of y is = 100.0\n",
      "And the corresponding coefficient vector is -\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "For gamma = 50:- percentage of error in predicted value of y is = 100.0\n",
      "And the corresponding coefficient vector is -\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "For gamma = 100:- percentage of error in predicted value of y is = 100.0\n",
      "And the corresponding coefficient vector is -\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "For gamma = 1000:- percentage of error in predicted value of y is = 100.0\n",
      "And the corresponding coefficient vector is -\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Testing with my own testset \n",
    "A = np.random.random((10,10))        #A matrix having basis vectors as it's columns\n",
    "y = np.random.random(10)             # Input vector (Note that this is not a 1-d matrix)     \n",
    "for gamma in [0.1, 0.5, 1, 2, 4, 6, 10, 20, 50, 100, 1000]:\n",
    "    x = feature_sign_search(A, y, gamma) #Coefficient vector \n",
    "    ydash = np.dot(A,x)                  #predicted input vector\n",
    "    print(\"For gamma = {0}:- percentage of error in predicted value of y is = {1}\".format(gamma,(((np.linalg.norm(y-ydash))/(np.linalg.norm(y)))*100)))\n",
    "    print(\"And the corresponding coefficient vector is -\")\n",
    "    print(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
